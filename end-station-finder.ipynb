{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Station Finder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge:\n",
    "My friend Lou has a project. They want to visit all the end stations on the Berlin S-Bahn and U-Bahn system. However, to count as a truly satisfying end station, the station must not only be at the end of its own line, but must also lack an interchange to another line. Lou wants only the end-iest of end stations.\n",
    "\n",
    "I want to find the end stations and present them to Lou in a format they can use for their project.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data:\n",
    "\n",
    "Berlin provides public transport data in the now-standard [GTFS](https://gtfs.org/) format, which stands for General (formerly Google) Transit Feed Specification. It is an [open standard](https://beyondtransparency.org/chapters/part-2/pioneering-open-data-standards-the-gtfs-story/) used by transit agencies to present their data in a uniform und useable way. It encompasses two types of data: realtime and static.\n",
    "- The realtime data is what drives (pun intended) our on-the-go transit apps and notifies us of delays and changes.\n",
    "- The static data (also known as *schedule data*) tells us and our apps about how all the points on the network are linked together. This is the GTFS data that will allow us identify the end stations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static GTFS data format\n",
    "GTFS is a data format in its own right, meant for \"[GTFS-consuming applications](https://www.transitwiki.org/TransitWiki/index.php/Category:GTFS-consuming_applications)\". However, conveniently, it is also easily readable in other software environements because it is merely a ZIP comprised of CSV (as TXT) files. The exact tables provided vary by agency. The following are the minimum required table files for static GTFS:\n",
    "-  `stops.txt` showing stops' name and location\n",
    "-  `stop_times.txt` showing every stop on every individual trip\n",
    "-  `trips.txt` showing trips' route, direction, destination* (headsign), and more\n",
    "-  `routes.txt` showing routes' transportation type, number, line colour, and more\n",
    "-  `agency.txt`\n",
    "\n",
    "My [download](https://daten.berlin.de/datensaetze/vbb-fahrplandaten-gtfs) for Berlin also contains these conditional and optional tables:\n",
    "-  `frequencies.txt`, `calendar.txt` and `calendar_dates.txt` showing service frequency, day and date availability\n",
    "-  `pathways.txt` and `levels.txt` showing platform positions inside stations\n",
    "-  `shapes.txt` showing a trip's path, expressed as a sequence of co-ordinates \n",
    "-  `transfers.txt` showing the connections between stations and details about these transfers\n",
    "\n",
    "GTFS does not contain a simple list of `stops` on `route`. Instead, `stop_ID`s appear as sequences of `stop_times` in individual `trips`, which in turn belong to various `routes`. We need to join the IDs of stops, trips and routes to the (giant) `stop_times.txt`. \n",
    "\n",
    "I would therefore need to combine the following tables and fields to find the end stations if I were to make a database:\n",
    "\n",
    "`stop_times.txt` for the sequence of stops\n",
    "- \"trip_id\"         (primary key 1) (foreign key of trips.trip_id)\n",
    "- \"stop_sequence\"   (primary key 2)\n",
    "- \"arrival_time\"\n",
    "- \"departure_time\"\n",
    "- \"stop_id\" (foreign key of stops.stop_id)\n",
    "- \"pickup_type\"\n",
    "- \"drop_off_type\"\n",
    "\n",
    "`transfers.txt` for the transfers between different routes (or in our case, the lack thereof)\n",
    "\n",
    "- \"from_stop_id\"    (primary key 1) (foreign key of stops.stop_id)\n",
    "- \"to_stop_id\"      (primary key 2) (foreign key 2 of stops.stop_id)\n",
    "- \"from_route_id\"   (primary key 3) - might not be needed\n",
    "- \"to_route_id\"     (primary key 4) - might not be needed\n",
    "- \"transfer_type\"`  see [docs](https://gtfs.org/schedule/reference/#transferstxt)\n",
    "- \"min_transfer_time\" \n",
    "\n",
    "`trips.txt` for matching the trip IDs to routes\n",
    "- \"trip_id\"         (primary key)\n",
    "- \"route_id\"        (foreign key of routes.route_id)\n",
    "- \"trip_headsign\"   *\n",
    "- \"trip_short_name\" (can be route number but appears not to be used for train numbers here)\n",
    "- \"direction_id\"\n",
    "\n",
    "`stops.txt` for matching the stop IDs to stops\n",
    "- \"stop_id\"         (primary key)\n",
    "- \"stop_name\"       \n",
    "- \"stop_lon\"\n",
    "- \"stop_lat\"\n",
    "\n",
    "\\* the \"headsign\" destination is not to be confused with the end of a line; some trips do not travel the whole route. In our data this is a text field rather than an ID."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for GTFS\n",
    "\n",
    "There are some [packages designed to handle GTFS data](https://gtfs.org/resources/gtfs) in Python, created by various developers. These are mainly used for geographical and frequency data. \n",
    "\n",
    "However, I found three that I may be able to use to find the end stations in **Python**, more easily than by manually creating a database:\n",
    "\n",
    "|    | Package | Data Structure | Potential Functions |\n",
    "| ---| ------- | -------------- | ------------------- |\n",
    "| 1.    | [`gtfs_kit`](https://mrcagney.github.io/gtfs_kit_docs/)   | Pandas  | `gtfs_kit.stops.get_stops` and `gtfs_kit.validators.check_transfers`|\n",
    "| 2. | [`transit_service_analyst`](https://github.com/psrc/transit_service_analyst/wiki/transit_service_analyst-documentation) | Pandas | `get_line_stops_gdf()` |\n",
    "| 3. | [`gtfs_utils`](https://open-bus-gtfs-utils.readthedocs.io/en/latest/route_stats.html)    | Pandas |  `route_stats` and `trip_stats`| \n",
    "\n",
    "I also noted down a few tools for **SQL**, in case the above don't work for me: \n",
    "1. [`node-gtfs`](https://github.com/BlinkTagInc/node-gtfs) SQLite\n",
    "2. [`gtfs-via-postgres`](https://github.com/public-transport/gtfs-via-postgres) PostgreSQL\n",
    "3. [`gtfs-schema`](https://github.com/tyleragreen/gtfs-schema) Schema builder\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load packages, extensions and data\n",
    "I installed the `transit_service_analyst` package first. It also requires `geopandas` and `pandera` to be installed. Now I can import the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transit_service_analyst as tsa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used the `tsa.load_gtfs(folder, service_date)` command to load the data. To do this it needs the location of the unzipped GTFS folder and a sample date from the dataset as arguments. It then loads the data into a Pandas dataframe.\n",
    "\n",
    "Note:\n",
    "Choosing only a single date to build the routes is a potential issue: `tsa` constructs the routes based on the stops served in all scheduled trips on the sample day, and I do not know if a date I choose at random will be representative of Berlin trains' optimal route activity. That is to say, in case of a known problem or construction work that prevents trains reaching their normal end station on our sample day, the scheduled trip data might show the end point as earlier than it is on the real route. I will attempt to overcome this later, probably by sampling various dates from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa.load_gtfs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
