{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Station Finder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge:\n",
    "My friend Lou has a project. They want to visit all the end stations on the Berlin S-Bahn and U-Bahn system. However, to count as a truly satisfying end station, the station must not only be at the end of its own line, but must also lack an interchange to another line. Lou wants only the end-iest of end stations.\n",
    "\n",
    "I want to find the end stations and present them to Lou in a format they can use for their project.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data:\n",
    "\n",
    "Berlin provides public transport data in the now-standard [GTFS](https://gtfs.org/) format, which stands for General (formerly Google) Transit Feed Specification. It is an [open standard](https://beyondtransparency.org/chapters/part-2/pioneering-open-data-standards-the-gtfs-story/) used by transit agencies to present their data in a uniform und useable way. It encompasses two types of data: realtime and static.\n",
    "- The realtime data is what drives (pun intended) our on-the-go transit apps and notifies us of delays and changes.\n",
    "- The static data (also known as *schedule data*) tells us and our apps about how all the points on the network are linked together. This is the GTFS data that will allow us identify the end stations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static GTFS data format\n",
    "GTFS is a data format in its own right, meant for \"[GTFS-consuming applications](https://www.transitwiki.org/TransitWiki/index.php/Category:GTFS-consuming_applications)\". However, conveniently, it is also easily readable in other software environements because it is merely a ZIP comprised of CSV (as TXT) files. The exact tables provided vary by agency. The following are the minimum required [table files for static GTFS](https://gtfs.org/schedule/reference/):\n",
    "-  `stops.txt` showing stops' name and location\n",
    "-  `stop_times.txt` showing every stop on every individual trip\n",
    "-  `trips.txt` showing trips' route, direction, destination* (headsign), and more\n",
    "-  `routes.txt` showing routes' transportation type, number, line colour, and more\n",
    "-  `agency.txt`\n",
    "\n",
    "My [GTFS download for Berlin](https://daten.berlin.de/datensaetze/vbb-fahrplandaten-gtfs) also contains these conditionally required and optional tables:\n",
    "-  `frequencies.txt` (note: empty), `calendar.txt` and `calendar_dates.txt` showing service frequency, day and date availability\n",
    "-  `pathways.txt` and `levels.txt` showing platform positions inside stations\n",
    "-  `shapes.txt` showing a trip's path, expressed as a sequence of co-ordinates \n",
    "-  `transfers.txt` showing the connections between stations and details about these transfers\n",
    "\n",
    "GTFS does not contain a simple list of `stops` on `route`. Instead, `stop_ID`s appear as sequences of `stop_times` in individual `trips`, which in turn belong to various `routes`. We need to join the IDs of stops, trips and routes to the (giant) `stop_times.txt`. \n",
    "\n",
    "I would therefore need to combine the following tables and fields to find the end stations if I were to make a database:\n",
    "\n",
    "`stop_times.txt` for the sequence of stops\n",
    "- \"trip_id\"         (primary key 1) (foreign key of trips.trip_id)\n",
    "- \"stop_sequence\"   (primary key 2)\n",
    "- \"arrival_time\"\n",
    "- \"departure_time\"\n",
    "- \"stop_id\" (foreign key of stops.stop_id)\n",
    "- \"pickup_type\"\n",
    "- \"drop_off_type\"\n",
    "\n",
    "`transfers.txt` for the transfers between different routes (or in our case, the lack thereof)\n",
    "\n",
    "- \"from_stop_id\"    (primary key 1) (foreign key of stops.stop_id)\n",
    "- \"to_stop_id\"      (primary key 2) (foreign key 2 of stops.stop_id)\n",
    "- \"from_route_id\"   (primary key 3) - might not be needed\n",
    "- \"to_route_id\"     (primary key 4) - might not be needed\n",
    "- \"transfer_type\"`  see [docs](https://gtfs.org/schedule/reference/#transferstxt)\n",
    "- \"min_transfer_time\" \n",
    "\n",
    "`trips.txt` for matching the trip IDs to routes\n",
    "- \"trip_id\"         (primary key)\n",
    "- \"route_id\"        (foreign key of routes.route_id)\n",
    "- \"trip_headsign\"   *\n",
    "- \"trip_short_name\" (can be route number but appears not to be used for train numbers here)\n",
    "- \"direction_id\"\n",
    "\n",
    "`stops.txt` for matching the stop IDs to stops\n",
    "- \"stop_id\"         (primary key)\n",
    "- \"stop_name\"       \n",
    "- \"stop_lon\"\n",
    "- \"stop_lat\"\n",
    "\n",
    "\\* the \"headsign\" destination is not to be confused with the end of a line; some trips do not travel the whole route. In our data this is a text field rather than an ID."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for GTFS\n",
    "\n",
    "There are many [packages designed to handle GTFS data](https://gtfs.org/resources/gtfs) in Python, created by various developers. These are mainly used for geographical and frequency data, but I found three that I may be able to use to find the end stations in **Python**, more easily than by manually creating a database:\n",
    "\n",
    "|    | Package | Data Structure | Potential Functions |\n",
    "| ---| ------- | -------------- | ------------------- |\n",
    "| 1.    | [`gtfs_kit`](https://mrcagney.github.io/gtfs_kit_docs/)   | Pandas  | `gtfs_kit.stops.get_stops` and `gtfs_kit.validators.check_transfers`|\n",
    "| 2. | [`transit_service_analyst`](https://github.com/psrc/transit_service_analyst/wiki/transit_service_analyst-documentation) | Pandas | `get_line_stops_gdf()` |\n",
    "| 3. | [`gtfs_utils`](https://open-bus-gtfs-utils.readthedocs.io/en/latest/route_stats.html)    | Pandas |  `route_stats` and `trip_stats`| \n",
    "\n",
    "I also noted down a few tools for **SQL**, in case the above don't work for me: \n",
    "1. [`node-gtfs`](https://github.com/BlinkTagInc/node-gtfs) SQLite\n",
    "2. [`gtfs-via-postgres`](https://github.com/public-transport/gtfs-via-postgres) PostgreSQL\n",
    "3. [`gtfs-schema`](https://github.com/tyleragreen/gtfs-schema) Schema builder\n",
    "4. [`gtfsdb`](https://github.com/OpenTransitTools/gtfsdb) Works with various SQL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: attempt with `transit_service_analyst`\n",
    "### Step 1: Load packages, extensions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import shapely.geometry\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to install and try the `transit_service_analyst` package first. It also requires `geopandas` and `pandera` to be installed. Now I can import the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transit_service_analyst as tsa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used the command `tsa.load_gtfs(folder, service_date)` to try to load the data into a Pandas dataframe. The required arguments are:\n",
    "- the location of the unzipped GTFS folder\n",
    "- a sample date from the dataset in YYYYMMDD form. \n",
    "\n",
    "A date is needed because `tsa` constructs the routes based on the stops served in all scheduled trips on the sample day. A look in `calendar.txt` shows that my data runs from 20230615 to 20231209, so I picked today, 20230705, a Wednesday.\n",
    "\n",
    "**Note on date and route sampling issues:**\n",
    "Choosing only a single date to build the routes is a potential issue because there is the possibility that it might not sample the whole length of routes. For example, in the case of construction work that prevents trains reaching their normal end station, the scheduled trip data might show an point earlier than the end of the physical route. This can be partially controlled for using information already contained in Berlin's GTFS data. Indeed, today, like most or maybe all days, is marked as an exception in `calendar_dates.txt`. Later I will check the affected `service_id`s to find out if they are relevant. However, this would not account for any shortened routes that span enough time to be counted as the normal schedule rather than the exception, and I will attempt to overcome this later, probably by sampling various dates from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_analyst = tsa.load_gtfs('Berlin GTFS data', '20230705')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i got an error: `Cannot set a DataFrame with multiple columns to the single column start_time_secs` [and other _time_secs columns]\n",
    "#attempting to debug and reload. \n",
    "#Autoreload lets me use the changes instantly without a kernel reload.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sian/anaconda3/envs/stats_env/lib/python3.9/site-packages/transit_service_analyst/gtfs_service.py:95: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_df = pd.read_csv(os.path.join(self.gtfs_dir, \"trips.txt\"))\n",
      "/home/sian/anaconda3/envs/stats_env/lib/python3.9/site-packages/transit_service_analyst/gtfs_service.py:116: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stop_times_df = pd.read_csv(os.path.join(self.gtfs_dir, \"stop_times.txt\"))\n"
     ]
    },
    {
     "ename": "SchemaErrors",
     "evalue": "Schema Routes: A total of 1 schema errors were found.\n\nError Counts\n------------\n- SchemaErrorReason.SCHEMA_COMPONENT_CHECK: 1\n\nSchema Error Summary\n--------------------\n                                                                                    failure_cases  n_failure_cases\nschema_context column     check                                                                                   \nColumn         route_type isin([0, 1, 2, 3, 4, 5, 6, 7, 11, 12])  [700, 100, 900, 1000, 109, 400]                6\n\nUsage Tip\n---------\n\nDirectly inspect all errors by catching the exception:\n\n```\ntry:\n    schema.validate(dataframe, lazy=True)\nexcept SchemaErrors as err:\n    err.failure_cases  # dataframe of schema errors\n    err.data  # invalid dataframe\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaErrors\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transit_analyst \u001b[39m=\u001b[39m tsa\u001b[39m.\u001b[39;49mload_gtfs(\u001b[39m'\u001b[39;49m\u001b[39mBerlin GTFS data\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m20230705\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/transit_service_analyst/load_gtfs.py:5\u001b[0m, in \u001b[0;36mload_gtfs\u001b[0;34m(gtfs_dir, service_date)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_gtfs\u001b[39m(gtfs_dir, service_date):\n\u001b[0;32m----> 5\u001b[0m     gtfs_service \u001b[39m=\u001b[39m Service_Utils(gtfs_dir, service_date)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m gtfs_service\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/transit_service_analyst/gtfs_service.py:38\u001b[0m, in \u001b[0;36mService_Utils.__init__\u001b[0;34m(self, gtfs_dir, service_date)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrips, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_times \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrequencies_to_trips()\n\u001b[1;32m     37\u001b[0m \u001b[39m# self._df_all_stops_by_trips = self.__get_trips_stop_times()\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroutes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_routes()\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_times[\u001b[39m\"\u001b[39m\u001b[39mstop_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstops \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_stops()\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/transit_service_analyst/gtfs_service.py:107\u001b[0m, in \u001b[0;36mService_Utils.__get_routes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mGets records in routes.txt for the trips that represent the\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mservice_date passed into the constructor. Returns a DataFrame.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m routes_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgtfs_dir, \u001b[39m\"\u001b[39m\u001b[39mroutes.txt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 107\u001b[0m routes_df \u001b[39m=\u001b[39m GTFS_Schema\u001b[39m.\u001b[39;49mRoutes\u001b[39m.\u001b[39;49mvalidate(routes_df, lazy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    108\u001b[0m routes_df \u001b[39m=\u001b[39m routes_df[routes_df[\u001b[39m\"\u001b[39m\u001b[39mroute_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrips[\u001b[39m\"\u001b[39m\u001b[39mroute_id\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m routes_df\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/pandera/api/pandas/model.py:304\u001b[0m, in \u001b[0;36mDataFrameModel.validate\u001b[0;34m(cls, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    290\u001b[0m \u001b[39m@docstring_substitution\u001b[39m(validate_doc\u001b[39m=\u001b[39mDataFrameSchema\u001b[39m.\u001b[39mvalidate\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     inplace: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrameBase[TDataFrameModel]:\n\u001b[1;32m    301\u001b[0m     \u001b[39m\"\"\"%(validate_doc)s\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    303\u001b[0m         DataFrameBase[TDataFrameModel],\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mto_schema()\u001b[39m.\u001b[39;49mvalidate(\n\u001b[1;32m    305\u001b[0m             check_obj, head, tail, sample, random_state, lazy, inplace\n\u001b[1;32m    306\u001b[0m         ),\n\u001b[1;32m    307\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/pandera/api/pandas/container.py:341\u001b[0m, in \u001b[0;36mDataFrameSchema.validate\u001b[0;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    329\u001b[0m     check_obj \u001b[39m=\u001b[39m check_obj\u001b[39m.\u001b[39mmap_partitions(  \u001b[39m# type: ignore [operator]\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate,\n\u001b[1;32m    331\u001b[0m         head\u001b[39m=\u001b[39mhead,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m         meta\u001b[39m=\u001b[39mcheck_obj,\n\u001b[1;32m    338\u001b[0m     )\n\u001b[1;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m check_obj\u001b[39m.\u001b[39mpandera\u001b[39m.\u001b[39madd_schema(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 341\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(\n\u001b[1;32m    342\u001b[0m     check_obj\u001b[39m=\u001b[39;49mcheck_obj,\n\u001b[1;32m    343\u001b[0m     head\u001b[39m=\u001b[39;49mhead,\n\u001b[1;32m    344\u001b[0m     tail\u001b[39m=\u001b[39;49mtail,\n\u001b[1;32m    345\u001b[0m     sample\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    346\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    347\u001b[0m     lazy\u001b[39m=\u001b[39;49mlazy,\n\u001b[1;32m    348\u001b[0m     inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    349\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/pandera/api/pandas/container.py:371\u001b[0m, in \u001b[0;36mDataFrameSchema._validate\u001b[0;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_inferred:\n\u001b[1;32m    363\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m is an inferred schema that hasn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt been \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodified. It\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms recommended that you refine the schema \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_backend(check_obj)\u001b[39m.\u001b[39;49mvalidate(\n\u001b[1;32m    372\u001b[0m     check_obj,\n\u001b[1;32m    373\u001b[0m     schema\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    374\u001b[0m     head\u001b[39m=\u001b[39;49mhead,\n\u001b[1;32m    375\u001b[0m     tail\u001b[39m=\u001b[39;49mtail,\n\u001b[1;32m    376\u001b[0m     sample\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    377\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    378\u001b[0m     lazy\u001b[39m=\u001b[39;49mlazy,\n\u001b[1;32m    379\u001b[0m     inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/stats_env/lib/python3.9/site-packages/pandera/backends/pandas/container.py:126\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.validate\u001b[0;34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    119\u001b[0m         error_handler\u001b[39m.\u001b[39mcollect_error(\n\u001b[1;32m    120\u001b[0m             result\u001b[39m.\u001b[39mreason_code,\n\u001b[1;32m    121\u001b[0m             error,\n\u001b[1;32m    122\u001b[0m             original_exc\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39moriginal_exc,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m error_handler\u001b[39m.\u001b[39mcollected_errors:\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mraise\u001b[39;00m SchemaErrors(\n\u001b[1;32m    127\u001b[0m         schema\u001b[39m=\u001b[39mschema,\n\u001b[1;32m    128\u001b[0m         schema_errors\u001b[39m=\u001b[39merror_handler\u001b[39m.\u001b[39mcollected_errors,\n\u001b[1;32m    129\u001b[0m         data\u001b[39m=\u001b[39mcheck_obj,\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m check_obj\n",
      "\u001b[0;31mSchemaErrors\u001b[0m: Schema Routes: A total of 1 schema errors were found.\n\nError Counts\n------------\n- SchemaErrorReason.SCHEMA_COMPONENT_CHECK: 1\n\nSchema Error Summary\n--------------------\n                                                                                    failure_cases  n_failure_cases\nschema_context column     check                                                                                   \nColumn         route_type isin([0, 1, 2, 3, 4, 5, 6, 7, 11, 12])  [700, 100, 900, 1000, 109, 400]                6\n\nUsage Tip\n---------\n\nDirectly inspect all errors by catching the exception:\n\n```\ntry:\n    schema.validate(dataframe, lazy=True)\nexcept SchemaErrors as err:\n    err.failure_cases  # dataframe of schema errors\n    err.data  # invalid dataframe\n```\n"
     ]
    }
   ],
   "source": [
    "transit_analyst = tsa.load_gtfs('Berlin GTFS data', '20230705')\n",
    "#routes_df failed Pandera schema validation and yielded another error so I added lazy=True to all dfs' validation in the source "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failures due to data compatibility issues\n",
    "\n",
    "#### Empty csv\n",
    "Unfortunately it seems like this package requires a populated `frequencies.txt` to gather the `trip_id`s. This csv is however empty in Berlin's static data. The code in `gtfs_service.py` was set up to deal with the file existing or not existing, but not being empty:\n",
    "\n",
    "```python\n",
    "if os.path.exists(os.path.join(self.gtfs_dir, \"frequencies.txt\")):\n",
    "            self.trips, self.stop_times = self.frequencies_to_trips()\n",
    "```\n",
    "Solved for now by renaming the file, but it would be good to suggest a change on Github later.\n",
    "\n",
    "#### Inconsistent `route_type`s\n",
    "Berlin's data uses [Google Transit extended route types](https://developers.google.com/transit/gtfs/reference/extended-route-types) rather than the classic [GTFS route types](https://gtfs.org/schedule/reference/#routestxt) so Pandera's schema validation fails:\n",
    "\n",
    "```console\n",
    "    Error Counts\n",
    "    ------------\n",
    "    - SchemaErrorReason.SCHEMA_COMPONENT_CHECK: 1\n",
    "    \n",
    "    Schema Error Summary\n",
    "    --------------------\n",
    "                                                                                        failure_cases  n_failure_cases\n",
    "    schema_context column     check                                                                                   \n",
    "    Column         route_type isin([0, 1, 2, 3, 4, 5, 6, 7, 11, 12])  [700, 100, 900, 1000, 109, 400]                6\n",
    "```\n",
    "\n",
    "Can I easily update the schema?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: attempt with [`gtfs_kit`](https://mrcagney.github.io/gtfs_kit_docs/)\n",
    "### Step 1: Load packages, extensions and data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed `gtfs_kit` in my conda envoronment and imported it. This module uses Pandas and Shapely to manipulate the GTFS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtfs_kit as gk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathways.txt</td>\n",
       "      <td>8946320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trips.txt</td>\n",
       "      <td>16658440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transfers.txt</td>\n",
       "      <td>3321256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agency.txt</td>\n",
       "      <td>3255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stops.txt</td>\n",
       "      <td>7201534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>routes.txt</td>\n",
       "      <td>48522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shapes.txt</td>\n",
       "      <td>163661343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>levels.txt</td>\n",
       "      <td>6098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0frequencies.txt</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>calendar_dates.txt</td>\n",
       "      <td>874177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stop_times.txt</td>\n",
       "      <td>382968429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>calendar.txt</td>\n",
       "      <td>94800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name  file_size\n",
       "0         pathways.txt    8946320\n",
       "1            trips.txt   16658440\n",
       "2        transfers.txt    3321256\n",
       "3           agency.txt       3255\n",
       "4            stops.txt    7201534\n",
       "5           routes.txt      48522\n",
       "6           shapes.txt  163661343\n",
       "7           levels.txt       6098\n",
       "8     0frequencies.txt         64\n",
       "9   calendar_dates.txt     874177\n",
       "10      stop_times.txt  382968429\n",
       "11        calendar.txt      94800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gk.list_feed('Berlin GTFS data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our GTFS data into an instance of the module's `Feed` class, ignoring non-GTFS files and stripping whitespaces from column names as it does so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/mrcagney/gtfs_kit/blob/master/notebooks/examples.ipynb\n",
    "feed = gk.read_feed('Berlin GTFS data', dist_units='km')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Feed` class has a specialised `describe()` method which shows us information about the component `DataFrame`s of our instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agencies</td>\n",
       "      <td>[S-Bahn Berlin GmbH, Oberhavel Verkehrsgesells...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timezone</td>\n",
       "      <td>Europe/Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_date</td>\n",
       "      <td>20230615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>end_date</td>\n",
       "      <td>20231209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_routes</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_trips</td>\n",
       "      <td>238544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_stops</td>\n",
       "      <td>41151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_shapes</td>\n",
       "      <td>14515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_date</td>\n",
       "      <td>20230622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_routes_active_on_sample_date</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_trips_active_on_sample_date</td>\n",
       "      <td>70501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num_stops_active_on_sample_date</td>\n",
       "      <td>25847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           indicator  \\\n",
       "0                           agencies   \n",
       "1                           timezone   \n",
       "2                         start_date   \n",
       "3                           end_date   \n",
       "4                         num_routes   \n",
       "5                          num_trips   \n",
       "6                          num_stops   \n",
       "7                         num_shapes   \n",
       "8                        sample_date   \n",
       "9   num_routes_active_on_sample_date   \n",
       "10   num_trips_active_on_sample_date   \n",
       "11   num_stops_active_on_sample_date   \n",
       "\n",
       "                                                value  \n",
       "0   [S-Bahn Berlin GmbH, Oberhavel Verkehrsgesells...  \n",
       "1                                       Europe/Berlin  \n",
       "2                                            20230615  \n",
       "3                                            20231209  \n",
       "4                                                1257  \n",
       "5                                              238544  \n",
       "6                                               41151  \n",
       "7                                               14515  \n",
       "8                                            20230622  \n",
       "9                                                1190  \n",
       "10                                              70501  \n",
       "11                                              25847  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: List stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm not sure which modules I need to import as well here...\n",
    "import shapely as shp\n",
    "import pyproj\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_routes = feed.get_routes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the Berlin data is using Extended GTFS journey types, I will extract the routes directly by number:\n",
    "- **109**: Suburban Railway.\tExamples:\tS-Bahn (DE)\n",
    "- **400**: Urban Railway Service   (note: not 402: Underground Service, despite U-Bahn being an example given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_color</th>\n",
       "      <th>route_text_color</th>\n",
       "      <th>route_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>21649_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>18950_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>18949_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>16814_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>12003_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>11561_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>11537_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>11536_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>10281_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>10277_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>10276_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10271_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10229_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>10227_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>10226_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>10224_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>10223_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>10170_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>10167_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>10166_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>10165_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10163_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>10162_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>10160_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>10159_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>10158_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>10157_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>10155_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>10154_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>10150_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10149_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10148_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>10145_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10144_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10143_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>10142_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10141_109</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>17526_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>F3791D</td>\n",
       "      <td>000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>17525_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>224F86</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>17523_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>528DBA</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>17521_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>8C6DAB</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>17518_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>7E5330</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>17516_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>F0D722</td>\n",
       "      <td>000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>17515_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>16683D</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>17514_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>DA421E</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>17512_400</td>\n",
       "      <td>796</td>\n",
       "      <td>U1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>7DAD4C</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>19159_109</td>\n",
       "      <td>108</td>\n",
       "      <td>S2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>19156_109</td>\n",
       "      <td>108</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>19155_109</td>\n",
       "      <td>108</td>\n",
       "      <td>S4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       route_id agency_id route_short_name route_long_name  route_type  \\\n",
       "151   21649_109         1              S25             NaN         109   \n",
       "152   18950_109         1               S3             NaN         109   \n",
       "153   18949_109         1              S26             NaN         109   \n",
       "154   16814_109         1               S7             NaN         109   \n",
       "156   12003_109         1              S85             NaN         109   \n",
       "157   11561_109         1               S3             NaN         109   \n",
       "158   11537_109         1              S46             NaN         109   \n",
       "159   11536_109         1              S46             NaN         109   \n",
       "165   10281_109         1               S8             NaN         109   \n",
       "166   10277_109         1               S1             NaN         109   \n",
       "167   10276_109         1               S1             NaN         109   \n",
       "169   10271_109         1               S9             NaN         109   \n",
       "171   10229_109         1              S47             NaN         109   \n",
       "172   10227_109         1              S42             NaN         109   \n",
       "173   10226_109         1              S42             NaN         109   \n",
       "174   10224_109         1              S41             NaN         109   \n",
       "175   10223_109         1              S41             NaN         109   \n",
       "176   10170_109         1               S9             NaN         109   \n",
       "177   10167_109         1               S8             NaN         109   \n",
       "178   10166_109         1              S75             NaN         109   \n",
       "179   10165_109         1              S75             NaN         109   \n",
       "180   10163_109         1               S7             NaN         109   \n",
       "181   10162_109         1               S7             NaN         109   \n",
       "182   10160_109         1               S5             NaN         109   \n",
       "183   10159_109         1               S5             NaN         109   \n",
       "184   10158_109         1               S5             NaN         109   \n",
       "185   10157_109         1               S5             NaN         109   \n",
       "186   10155_109         1              S46             NaN         109   \n",
       "187   10154_109         1              S45             NaN         109   \n",
       "188   10150_109         1               S3             NaN         109   \n",
       "189   10149_109         1               S3             NaN         109   \n",
       "190   10148_109         1               S3             NaN         109   \n",
       "191   10145_109         1              S25             NaN         109   \n",
       "192   10144_109         1               S2             NaN         109   \n",
       "193   10143_109         1               S2             NaN         109   \n",
       "194   10142_109         1               S1             NaN         109   \n",
       "195   10141_109         1               S1             NaN         109   \n",
       "400   17526_400       796               U9             NaN         400   \n",
       "401   17525_400       796               U8             NaN         400   \n",
       "402   17523_400       796               U7             NaN         400   \n",
       "403   17521_400       796               U6             NaN         400   \n",
       "405   17518_400       796               U5             NaN         400   \n",
       "406   17516_400       796               U4             NaN         400   \n",
       "407   17515_400       796               U3             NaN         400   \n",
       "408   17514_400       796               U2             NaN         400   \n",
       "409   17512_400       796               U1             NaN         400   \n",
       "1079  19159_109       108               S2             NaN         109   \n",
       "1081  19156_109       108               S1             NaN         109   \n",
       "1082  19155_109       108               S4             NaN         109   \n",
       "\n",
       "     route_color route_text_color route_desc  \n",
       "151          NaN              NaN        NaN  \n",
       "152          NaN              NaN        NaN  \n",
       "153          NaN              NaN        NaN  \n",
       "154          NaN              NaN        NaN  \n",
       "156          NaN              NaN        NaN  \n",
       "157          NaN              NaN        NaN  \n",
       "158          NaN              NaN        NaN  \n",
       "159          NaN              NaN        NaN  \n",
       "165          NaN              NaN        NaN  \n",
       "166          NaN              NaN        NaN  \n",
       "167          NaN              NaN        NaN  \n",
       "169          NaN              NaN        NaN  \n",
       "171          NaN              NaN        NaN  \n",
       "172          NaN              NaN        NaN  \n",
       "173          NaN              NaN        NaN  \n",
       "174          NaN              NaN        NaN  \n",
       "175          NaN              NaN        NaN  \n",
       "176          NaN              NaN        NaN  \n",
       "177          NaN              NaN        NaN  \n",
       "178          NaN              NaN        NaN  \n",
       "179          NaN              NaN        NaN  \n",
       "180          NaN              NaN        NaN  \n",
       "181          NaN              NaN        NaN  \n",
       "182          NaN              NaN        NaN  \n",
       "183          NaN              NaN        NaN  \n",
       "184          NaN              NaN        NaN  \n",
       "185          NaN              NaN        NaN  \n",
       "186          NaN              NaN        NaN  \n",
       "187          NaN              NaN        NaN  \n",
       "188          NaN              NaN        NaN  \n",
       "189          NaN              NaN        NaN  \n",
       "190          NaN              NaN        NaN  \n",
       "191          NaN              NaN        NaN  \n",
       "192          NaN              NaN        NaN  \n",
       "193          NaN              NaN        NaN  \n",
       "194          NaN              NaN        NaN  \n",
       "195          NaN              NaN        NaN  \n",
       "400       F3791D           000000        NaN  \n",
       "401       224F86           FFFFFF        NaN  \n",
       "402       528DBA           FFFFFF        NaN  \n",
       "403       8C6DAB           FFFFFF        NaN  \n",
       "405       7E5330           FFFFFF        NaN  \n",
       "406       F0D722           000000        NaN  \n",
       "407       16683D           FFFFFF        NaN  \n",
       "408       DA421E           FFFFFF        NaN  \n",
       "409       7DAD4C           FFFFFF        NaN  \n",
       "1079         NaN              NaN        NaN  \n",
       "1081         NaN              NaN        NaN  \n",
       "1082         NaN              NaN        NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_routes[(berlin_routes.route_type == 109) | (berlin_routes.route_type == 400)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the type is also appended in the `route_id`.\n",
    "\n",
    "However, it's not immedately obvious how to link the routes and the individual stops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_code</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_desc</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>location_type</th>\n",
       "      <th>parent_station</th>\n",
       "      <th>wheelchair_boarding</th>\n",
       "      <th>platform_code</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de:11000:900100007::3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S Oranienburger Str. (Berlin)</td>\n",
       "      <td>Ersatzhalt Tucholskystrae vor Oranienburger S...</td>\n",
       "      <td>52.524724</td>\n",
       "      <td>13.392833</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5555 S Oranienburger Str. (Berlin)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de:12070:900215110:1:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bad Wilsnack, Bahnhof</td>\n",
       "      <td>Bahnsteig Gleis 2</td>\n",
       "      <td>52.960114</td>\n",
       "      <td>11.949402</td>\n",
       "      <td>0</td>\n",
       "      <td>de:12070:900215110</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4533 Bad Wilsnack, Bahnhof</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de:12070:900215110:2:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bad Wilsnack, Bahnhof</td>\n",
       "      <td>Bahnsteig Gleis 3</td>\n",
       "      <td>52.960219</td>\n",
       "      <td>11.949528</td>\n",
       "      <td>0</td>\n",
       "      <td>de:12070:900215110</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4533 Bad Wilsnack, Bahnhof</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de:12062:900415465:1:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prsen, Bahnhof</td>\n",
       "      <td>Bahnsteig Gleis 1</td>\n",
       "      <td>51.434919</td>\n",
       "      <td>13.488216</td>\n",
       "      <td>0</td>\n",
       "      <td>de:12062:900415465</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7958 Prsen, Bahnhof</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de:12062:900415465:2:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prsen, Bahnhof</td>\n",
       "      <td>Bahnsteig Gleis 2</td>\n",
       "      <td>51.434886</td>\n",
       "      <td>13.488277</td>\n",
       "      <td>0</td>\n",
       "      <td>de:12062:900415465</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7958 Prsen, Bahnhof</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stop_id stop_code                      stop_name  \\\n",
       "0    de:11000:900100007::3       NaN  S Oranienburger Str. (Berlin)   \n",
       "1  de:12070:900215110:1:50       NaN          Bad Wilsnack, Bahnhof   \n",
       "2  de:12070:900215110:2:51       NaN          Bad Wilsnack, Bahnhof   \n",
       "3  de:12062:900415465:1:50       NaN                Prsen, Bahnhof   \n",
       "4  de:12062:900415465:2:51       NaN                Prsen, Bahnhof   \n",
       "\n",
       "                                           stop_desc   stop_lat   stop_lon  \\\n",
       "0  Ersatzhalt Tucholskystrae vor Oranienburger S...  52.524724  13.392833   \n",
       "1                                  Bahnsteig Gleis 2  52.960114  11.949402   \n",
       "2                                  Bahnsteig Gleis 3  52.960219  11.949528   \n",
       "3                                  Bahnsteig Gleis 1  51.434919  13.488216   \n",
       "4                                  Bahnsteig Gleis 2  51.434886  13.488277   \n",
       "\n",
       "   location_type      parent_station  wheelchair_boarding platform_code  \\\n",
       "0              0                 NaN                    0           NaN   \n",
       "1              0  de:12070:900215110                    1             2   \n",
       "2              0  de:12070:900215110                    1             3   \n",
       "3              0  de:12062:900415465                    1             1   \n",
       "4              0  de:12062:900415465                    1             2   \n",
       "\n",
       "                              zone_id  level_id  \n",
       "0  5555 S Oranienburger Str. (Berlin)       4.0  \n",
       "1          4533 Bad Wilsnack, Bahnhof      50.0  \n",
       "2          4533 Bad Wilsnack, Bahnhof      50.0  \n",
       "3                7958 Prsen, Bahnhof       4.0  \n",
       "4                7958 Prsen, Bahnhof       4.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.get_stops().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does not work..\n",
    "# tt = feed.build_route_timetable(route_id='17512', dates='20230707')\n",
    "# tt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stop_times` has a trip_id, stop_id and stop_sequence, but we would still need to join the routes and the number of connections. at this point there seems to be no advantage over importing it myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>stop_headsign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200164528</td>\n",
       "      <td>5:33:00</td>\n",
       "      <td>5:33:00</td>\n",
       "      <td>de:12068:900205112::1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200164528</td>\n",
       "      <td>5:34:00</td>\n",
       "      <td>5:34:00</td>\n",
       "      <td>de:12068:900205155::1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200164528</td>\n",
       "      <td>5:35:00</td>\n",
       "      <td>5:35:00</td>\n",
       "      <td>de:12068:900205110::1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200164528</td>\n",
       "      <td>5:37:00</td>\n",
       "      <td>5:37:00</td>\n",
       "      <td>de:12068:900205576::1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200164528</td>\n",
       "      <td>5:38:00</td>\n",
       "      <td>5:38:00</td>\n",
       "      <td>de:12068:900205577::1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476106</th>\n",
       "      <td>209074811</td>\n",
       "      <td>7:12:00</td>\n",
       "      <td>7:12:00</td>\n",
       "      <td>de:12064:900320850::1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476107</th>\n",
       "      <td>209074811</td>\n",
       "      <td>7:13:00</td>\n",
       "      <td>7:13:00</td>\n",
       "      <td>de:12064:900320843::2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476108</th>\n",
       "      <td>209074811</td>\n",
       "      <td>7:15:00</td>\n",
       "      <td>7:15:00</td>\n",
       "      <td>de:12064:900320832::4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476109</th>\n",
       "      <td>209074811</td>\n",
       "      <td>7:34:00</td>\n",
       "      <td>7:34:00</td>\n",
       "      <td>de:12064:900320553::1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476110</th>\n",
       "      <td>209074811</td>\n",
       "      <td>7:39:00</td>\n",
       "      <td>7:39:00</td>\n",
       "      <td>de:12064:900320025::2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5476111 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id arrival_time departure_time                stop_id  \\\n",
       "0        200164528      5:33:00        5:33:00  de:12068:900205112::1   \n",
       "1        200164528      5:34:00        5:34:00  de:12068:900205155::1   \n",
       "2        200164528      5:35:00        5:35:00  de:12068:900205110::1   \n",
       "3        200164528      5:37:00        5:37:00  de:12068:900205576::1   \n",
       "4        200164528      5:38:00        5:38:00  de:12068:900205577::1   \n",
       "...            ...          ...            ...                    ...   \n",
       "5476106  209074811      7:12:00        7:12:00  de:12064:900320850::1   \n",
       "5476107  209074811      7:13:00        7:13:00  de:12064:900320843::2   \n",
       "5476108  209074811      7:15:00        7:15:00  de:12064:900320832::4   \n",
       "5476109  209074811      7:34:00        7:34:00  de:12064:900320553::1   \n",
       "5476110  209074811      7:39:00        7:39:00  de:12064:900320025::2   \n",
       "\n",
       "         stop_sequence  pickup_type  drop_off_type stop_headsign  \n",
       "0                    0            0              0           NaN  \n",
       "1                    1            0              0           NaN  \n",
       "2                    2            0              0           NaN  \n",
       "3                    3            0              0           NaN  \n",
       "4                    4            0              0           NaN  \n",
       "...                ...          ...            ...           ...  \n",
       "5476106              6            0              0           NaN  \n",
       "5476107              7            0              0           NaN  \n",
       "5476108              8            0              0           NaN  \n",
       "5476109              9            0              0           NaN  \n",
       "5476110             10            0              0           NaN  \n",
       "\n",
       "[5476111 rows x 8 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.stop_times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: attempt with SQL or Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
